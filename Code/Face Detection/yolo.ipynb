{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvzone\n",
    "from ultralytics import YOLO\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 face, 183.7ms\n",
      "Speed: 16.1ms preprocess, 183.7ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 93.6ms\n",
      "Speed: 6.1ms preprocess, 93.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 85.5ms\n",
      "Speed: 2.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 121.1ms\n",
      "Speed: 2.0ms preprocess, 121.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 137.0ms\n",
      "Speed: 4.0ms preprocess, 137.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 92.6ms\n",
      "Speed: 3.0ms preprocess, 92.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 90.0ms\n",
      "Speed: 3.0ms preprocess, 90.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 91.2ms\n",
      "Speed: 4.0ms preprocess, 91.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 160.1ms\n",
      "Speed: 3.0ms preprocess, 160.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 98.2ms\n",
      "Speed: 3.0ms preprocess, 98.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 92.2ms\n",
      "Speed: 5.0ms preprocess, 92.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 78.6ms\n",
      "Speed: 3.0ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 103.4ms\n",
      "Speed: 5.1ms preprocess, 103.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 86.2ms\n",
      "Speed: 3.0ms preprocess, 86.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 84.5ms\n",
      "Speed: 3.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 75.6ms\n",
      "Speed: 3.0ms preprocess, 75.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 81.6ms\n",
      "Speed: 2.0ms preprocess, 81.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 87.3ms\n",
      "Speed: 2.0ms preprocess, 87.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 92.5ms\n",
      "Speed: 2.5ms preprocess, 92.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 77.0ms\n",
      "Speed: 3.0ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 77.3ms\n",
      "Speed: 2.6ms preprocess, 77.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 71.9ms\n",
      "Speed: 3.0ms preprocess, 71.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 74.3ms\n",
      "Speed: 3.0ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 80.3ms\n",
      "Speed: 2.0ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 70.9ms\n",
      "Speed: 3.0ms preprocess, 70.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 75.3ms\n",
      "Speed: 2.0ms preprocess, 75.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 78.1ms\n",
      "Speed: 2.0ms preprocess, 78.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 75.2ms\n",
      "Speed: 3.0ms preprocess, 75.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 72.6ms\n",
      "Speed: 2.0ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 76.0ms\n",
      "Speed: 4.0ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 84.8ms\n",
      "Speed: 2.0ms preprocess, 84.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 95.7ms\n",
      "Speed: 3.0ms preprocess, 95.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 86.9ms\n",
      "Speed: 2.6ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 90.3ms\n",
      "Speed: 4.3ms preprocess, 90.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 79.2ms\n",
      "Speed: 5.9ms preprocess, 79.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 84.4ms\n",
      "Speed: 2.0ms preprocess, 84.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 82.3ms\n",
      "Speed: 3.0ms preprocess, 82.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 81.8ms\n",
      "Speed: 2.0ms preprocess, 81.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 80.6ms\n",
      "Speed: 3.3ms preprocess, 80.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 87.1ms\n",
      "Speed: 3.0ms preprocess, 87.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 76.6ms\n",
      "Speed: 4.0ms preprocess, 76.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 75.5ms\n",
      "Speed: 3.0ms preprocess, 75.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 78.7ms\n",
      "Speed: 4.0ms preprocess, 78.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 79.2ms\n",
      "Speed: 3.0ms preprocess, 79.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 79.6ms\n",
      "Speed: 3.0ms preprocess, 79.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 77.7ms\n",
      "Speed: 3.0ms preprocess, 77.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 83.3ms\n",
      "Speed: 3.0ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 87.2ms\n",
      "Speed: 3.0ms preprocess, 87.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 109.8ms\n",
      "Speed: 3.3ms preprocess, 109.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 85.8ms\n",
      "Speed: 3.0ms preprocess, 85.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 90.6ms\n",
      "Speed: 2.0ms preprocess, 90.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 81.1ms\n",
      "Speed: 3.0ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 86.8ms\n",
      "Speed: 3.0ms preprocess, 86.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 69.6ms\n",
      "Speed: 3.0ms preprocess, 69.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 74.5ms\n",
      "Speed: 2.0ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 73.5ms\n",
      "Speed: 3.0ms preprocess, 73.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 70.8ms\n",
      "Speed: 3.0ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 75.6ms\n",
      "Speed: 2.0ms preprocess, 75.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Access the default laptop camera\n",
    "cap = cv2.VideoCapture(0)  # 0 is the default camera index\n",
    "\n",
    "# Load the YOLO model pretrained for face detection\n",
    "facemodel = YOLO(r\"D:\\PythonProject\\Face_Recognition_DL\\model\\yolov8n-face.pt\")  # Ensure you have the YOLOv8 face model file\n",
    "\n",
    "# Loop to continuously read frames from the camera\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()  # Capture a frame from the camera\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Resize the frame for consistent processing (optional)\n",
    "    frame = cv2.resize(frame, (700, 500))\n",
    "\n",
    "    # Perform face detection\n",
    "    face_results = facemodel.predict(frame, conf=0.40)  # Confidence threshold\n",
    "\n",
    "    # Process the detection results\n",
    "    for result in face_results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            # Get bounding box coordinates\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "\n",
    "            # Draw a fancy rectangle around the detected face\n",
    "            cvzone.cornerRect(frame, [x1, y1, w, h], l=9, rt=3)\n",
    "\n",
    "    # Display the frame with detected faces\n",
    "    cv2.imshow('Face Detection - YOLOv8', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\PythonProject\\\\Face_Recognition_DL\\\\Multiple_selfie.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the image\u001b[39;00m\n\u001b[0;32m      9\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPythonProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFace_Recognition_DL\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMultiple_selfie.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change this to your image path\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Resize the image for consistent processing\u001b[39;00m\n\u001b[0;32m     13\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m600\u001b[39m, \u001b[38;5;241m500\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\utils\\patches.py:26\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    Read an image from a file.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mimdecode(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m, flags)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\PythonProject\\\\Face_Recognition_DL\\\\Multiple_selfie.jpg'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cvzone\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO model pretrained for face detection\n",
    "facemodel = YOLO(r\"D:\\PythonProject\\Face_Recognition_DL\\model\\yolov8n-face.pt\")  # Ensure you have the YOLOv8 face model file\n",
    "\n",
    "# Load the image\n",
    "image_path = r\"D:\\PythonProject\\Face_Recognition_DL\\Multiple_selfie.jpg\"  # Change this to your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Resize the image for consistent processing\n",
    "image = cv2.resize(image, (600, 500))\n",
    "\n",
    "# Perform face detection\n",
    "face_results = facemodel.predict(image, conf=0.40)  # Confidence threshold\n",
    "\n",
    "# Process the detection results\n",
    "for result in face_results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        # Get bounding box coordinates\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "\n",
    "        # Draw a fancy rectangle around the detected face\n",
    "        cvzone.cornerRect(image, [x1, y1, w, h], l=9, rt=3)\n",
    "\n",
    "# Display the image with detected faces\n",
    "cv2.imshow('Face Detection - YOLOv8', image)\n",
    "cv2.imwrite(r\"D:\\PythonProject\\Face_Recognition_DL\\Face_detection_test_op\\YOLO.jpg\", image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

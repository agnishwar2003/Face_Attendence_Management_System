{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading face detection and recognition models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonProject\\Face_Recognition_DL\\HogEnv\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\PythonProject\\Face_Recognition_DL\\HogEnv\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting video stream...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths to model files and recognizer\n",
    "embeddingModel = r\"D:\\PythonProject\\Face_Recognition_DL\\openface.nn4.small2.v1.t7\"\n",
    "recognizerFile = r\"D:\\PythonProject\\Face_Recognition_DL\\output\\recognizer_updated_Openface01.pickle\"\n",
    "labelEncFile = r\"D:\\PythonProject\\Face_Recognition_DL\\output\\le_updated_Openface01.pickle\"\n",
    "conf_threshold = 0.8  # Confidence threshold\n",
    "\n",
    "# Paths to the face detection model (SSD)\n",
    "prototxt_path = r\"D:\\PythonProject\\Face_Recognition_DL\\model\\deploy.prototxt.txt\"\n",
    "model_path = r\"D:\\PythonProject\\Face_Recognition_DL\\model\\res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "detection_threshold = 0.5\n",
    "\n",
    "# Load models\n",
    "print(\"[INFO] Loading face detection and recognition models...\")\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
    "embedder = cv2.dnn.readNetFromTorch(embeddingModel)\n",
    "recognizer = pickle.loads(open(recognizerFile, \"rb\").read())\n",
    "le = pickle.loads(open(labelEncFile, \"rb\").read())\n",
    "\n",
    "# Initialize camera stream\n",
    "print(\"[INFO] Starting video stream...\")\n",
    "cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "time.sleep(2.0)\n",
    "\n",
    "# Create directory for recognized faces\n",
    "if not os.path.exists(\"recognized_faces\"):\n",
    "    os.makedirs(\"recognized_faces\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    \n",
    "    frame = imutils.resize(frame, width=640)  # Resize for performance\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    faceBlobs, boxes = [], []\n",
    "    \n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence < detection_threshold:\n",
    "            continue\n",
    "        \n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        \n",
    "        if startX < 0 or startY < 0 or endX > w or endY > h:\n",
    "            continue\n",
    "        \n",
    "        face = frame[startY:endY, startX:endX]\n",
    "        if face.shape[0] == 0 or face.shape[1] == 0:\n",
    "            continue\n",
    "        \n",
    "        faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "        faceBlobs.append(faceBlob)\n",
    "        boxes.append((startX, startY, endX, endY))\n",
    "    \n",
    "    if len(faceBlobs) > 0:\n",
    "        faceBlobs = np.vstack(faceBlobs)\n",
    "        embedder.setInput(faceBlobs)\n",
    "        vecs = embedder.forward()\n",
    "        \n",
    "        for i, vec in enumerate(vecs):\n",
    "            preds = recognizer.predict_proba([vec.flatten()])[0]\n",
    "            j = np.argmax(preds)\n",
    "            proba = preds[j]\n",
    "            name = le.classes_[j] if proba * 100 >= 65 else \"Unknown\"\n",
    "            \n",
    "            (startX, startY, endX, endY) = boxes[i]\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 1)\n",
    "            cv2.putText(frame, f\"{name}: {proba*100:.2f}%\", (startX, startY - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 1)\n",
    "            \n",
    "            if name != \"Unknown\":\n",
    "                timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "                cv2.imwrite(f\"recognized_faces/{name}_{timestamp}.jpg\", frame[startY:endY, startX:endX])\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    if cv2.getWindowProperty(\"Frame\", cv2.WND_PROP_VISIBLE) < 1:  # Close button clicked\n",
    "        break\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # ESC key to quit\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arc Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading YOLO model...\n",
      "[INFO] Loading face recognizer...\n",
      "[INFO] Loading stored face embeddings...\n",
      "[INFO] Starting video stream...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonProject\\Face_Recognition_DL\\HogEnv\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\PythonProject\\Face_Recognition_DL\\HogEnv\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 face, 70.9ms\n",
      "Speed: 4.0ms preprocess, 70.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "WARNING:tensorflow:From d:\\PythonProject\\Face_Recognition_DL\\HogEnv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Recognized: Sayan_FR, Probability: 81.81%\n",
      "\n",
      "0: 480x640 1 face, 222.5ms\n",
      "Speed: 44.8ms preprocess, 222.5ms inference, 25.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Recognized: Unknown, Probability: 41.16%\n",
      "\n",
      "0: 480x640 1 face, 102.0ms\n",
      "Speed: 3.5ms preprocess, 102.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Recognized: Unknown, Probability: 54.51%\n",
      "\n",
      "0: 480x640 1 face, 92.0ms\n",
      "Speed: 3.1ms preprocess, 92.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Recognized: Unknown, Probability: 39.40%\n",
      "\n",
      "0: 480x640 1 face, 89.4ms\n",
      "Speed: 2.5ms preprocess, 89.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Recognized: Unknown, Probability: 37.07%\n",
      "\n",
      "0: 480x640 1 face, 80.4ms\n",
      "Speed: 5.7ms preprocess, 80.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Recognized: Unknown, Probability: 35.81%\n"
     ]
    }
   ],
   "source": [
    "#ArcFace\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import imutils\n",
    "\n",
    "# Paths to model files and recognizer\n",
    "recognizerFile = r\"D:\\PythonProject\\Face_Recognition_DL\\output\\recognizer_updated_arc.pickle\"\n",
    "labelEncFile = r\"D:\\PythonProject\\Face_Recognition_DL\\output\\le_updated_arc.pickle\"\n",
    "embeddingFile = r\"D:\\PythonProject\\Face_Recognition_DL\\output\\embeddings_arcface.pickle\"\n",
    "yolo_model_path = r\"D:\\PythonProject\\Face_Recognition_DL\\model\\yolov8n-face.pt\"\n",
    "conf = 0.8  # Confidence threshold\n",
    "\n",
    "# Load YOLO model for face detection\n",
    "print(\"[INFO] Loading YOLO model...\")\n",
    "yolo = YOLO(yolo_model_path)\n",
    "\n",
    "# Load the face recognizer and label encoder\n",
    "print(\"[INFO] Loading face recognizer...\")\n",
    "recognizer = pickle.loads(open(recognizerFile, \"rb\").read())\n",
    "le = pickle.loads(open(labelEncFile, \"rb\").read())\n",
    "\n",
    "# Load saved embeddings\n",
    "print(\"[INFO] Loading stored face embeddings...\")\n",
    "data = pickle.loads(open(embeddingFile, \"rb\").read())\n",
    "known_embeddings = np.array(data[\"embeddings\"])\n",
    "known_names = np.array(data[\"names\"])\n",
    "\n",
    "# Initialize camera stream\n",
    "print(\"[INFO] Starting video stream...\")\n",
    "cam = cv2.VideoCapture(0)\n",
    "time.sleep(2.0)\n",
    "\n",
    "def get_embedding(face_img):\n",
    "    \"\"\"Extract embedding using DeepFace ArcFace.\"\"\"\n",
    "    from deepface import DeepFace\n",
    "    try:\n",
    "        embedding = DeepFace.represent(face_img, model_name='ArcFace', detector_backend='retinaface', enforce_detection=False)\n",
    "        return np.array(embedding[0]['embedding'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = imutils.resize(frame, width=600)\n",
    "\n",
    "    # Perform YOLO-based face detection\n",
    "    results = yolo.predict(frame, conf=0.4)\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            face = frame[y1:y2, x1:x2]\n",
    "            (fH, fW) = face.shape[:2]\n",
    "\n",
    "            # Skip small faces\n",
    "            if fW < 20 or fH < 20:\n",
    "                continue\n",
    "\n",
    "            # Extract embedding\n",
    "            embedding = get_embedding(face)\n",
    "            if embedding is None:\n",
    "                continue  # Skip if embedding extraction fails\n",
    "\n",
    "            # Perform recognition\n",
    "            preds = recognizer.predict_proba([embedding])[0]\n",
    "            j = np.argmax(preds)\n",
    "            proba = preds[j]\n",
    "            name = le.classes_[j]\n",
    "\n",
    "            # If recognition confidence is low, classify as \"Unknown\"\n",
    "            if proba * 100 < 70:\n",
    "                name = \"Unknown\"\n",
    "\n",
    "            # Draw bounding box and recognition text\n",
    "            text = f\"{name} : {proba * 100:.2f}%\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "            print(f\"Recognized: {name}, Probability: {proba * 100:.2f}%\")\n",
    "\n",
    "    # Show the output frame\n",
    "    cv2.imshow(\"YOLO Face Recognition\", frame)\n",
    "\n",
    "    if cv2.getWindowProperty(\"YOLO Face Recognition\", cv2.WND_PROP_VISIBLE) < 1:  # Close button clicked\n",
    "        break\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # ESC key to quit\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HogEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

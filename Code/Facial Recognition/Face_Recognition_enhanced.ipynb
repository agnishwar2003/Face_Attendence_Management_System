{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df222381",
   "metadata": {},
   "source": [
    "### GFGGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a336de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonProject\\Face_Recognition_DL\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading face detector...\n",
      "[INFO] Loading face embedder...\n",
      "[INFO] Loading recognizer and label encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonProject\\Face_Recognition_DL\\.venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\PythonProject\\Face_Recognition_DL\\.venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading GFPGAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonProject\\Face_Recognition_DL\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\PythonProject\\Face_Recognition_DL\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting video stream...\n",
      "[INFO] Recognized: Srijani_Test_Dataset, Probability: 100.00%\n",
      "[INFO] Recognized: Agnishwar_Das, Probability: 90.14%\n",
      "[INFO] Recognized: Srijani_Test_Dataset, Probability: 66.82%\n",
      "[INFO] Recognized: Srijani_Test_Dataset, Probability: 80.10%\n",
      "[INFO] Recognized: Agnishwar_Das, Probability: 93.38%\n",
      "[INFO] Recognized: Srijani_Test_Dataset, Probability: 73.55%\n",
      "[INFO] Recognized: Srijani_Test_Dataset, Probability: 84.88%\n",
      "[INFO] Recognized: Agnishwar_Das, Probability: 62.06%\n",
      "[INFO] Recognized: Srijani_Test_Dataset, Probability: 93.62%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "from gfpgan import GFPGANer\n",
    "\n",
    "# === Paths ===\n",
    "embeddingModel = r\"D:\\PythonProject\\Face_Recognition_DL\\openface.nn4.small2.v1.t7\"\n",
    "recognizerFile = r\"D:\\PythonProject\\Face_Recognition_DL\\Output_Models\\recognizer_Openface01.pickle\"\n",
    "labelEncFile = r\"D:\\PythonProject\\Face_Recognition_DL\\Output_Models\\LE_Openface01.pickle\"\n",
    "prototxt_path = r\"D:\\PythonProject\\Face_Recognition_DL\\model\\deploy.prototxt.txt\"\n",
    "model_path = r\"D:\\PythonProject\\Face_Recognition_DL\\model\\res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "gfpgan_model_path = r\"D:\\PythonProject\\Face_Recognition_DL\\model\\GFPGANv1.4.pth\"\n",
    "\n",
    "# === Configuration ===\n",
    "face_conf_threshold = 0.5\n",
    "recognition_conf_threshold = 0.5\n",
    "\n",
    "# === Load models ===\n",
    "print(\"[INFO] Loading face detector...\")\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
    "\n",
    "print(\"[INFO] Loading face embedder...\")\n",
    "embedder = cv2.dnn.readNetFromTorch(embeddingModel)\n",
    "\n",
    "print(\"[INFO] Loading recognizer and label encoder...\")\n",
    "recognizer = pickle.loads(open(recognizerFile, \"rb\").read())\n",
    "le = pickle.loads(open(labelEncFile, \"rb\").read())\n",
    "\n",
    "print(\"[INFO] Loading GFPGAN model...\")\n",
    "gfpgan = GFPGANer(\n",
    "    model_path=gfpgan_model_path,\n",
    "    upscale=1,\n",
    "    arch='clean',\n",
    "    channel_multiplier=2,\n",
    "    bg_upsampler=None\n",
    ")\n",
    "\n",
    "# === Start webcam ===\n",
    "print(\"[INFO] Starting video stream...\")\n",
    "cam = cv2.VideoCapture(0)\n",
    "time.sleep(2.0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = imutils.resize(frame, width=600)\n",
    "    (h, w) = frame.shape[:2]\n",
    "\n",
    "    # Detect faces using DNN\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,\n",
    "                                 (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence < face_conf_threshold:\n",
    "            continue\n",
    "\n",
    "        # Get face bounding box\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "        face = frame[startY:endY, startX:endX]\n",
    "        (fH, fW) = face.shape[:2]\n",
    "\n",
    "        if fW < 20 or fH < 20:\n",
    "            continue\n",
    "\n",
    "        # === Enhance face using GFPGAN ===\n",
    "        try:\n",
    "            face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            _, restored_faces, _ = gfpgan.enhance(\n",
    "                face_rgb, has_aligned=False, only_center_face=True, paste_back=False\n",
    "            )\n",
    "            enhanced_face = cv2.cvtColor(restored_faces[0], cv2.COLOR_RGB2BGR)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] GFPGAN enhancement failed: {e}\")\n",
    "            enhanced_face = face\n",
    "\n",
    "        # === Face recognition ===\n",
    "        faceBlob = cv2.dnn.blobFromImage(enhanced_face, 1.0 / 255, (96, 96),\n",
    "                                         (0, 0, 0), swapRB=True, crop=False)\n",
    "        embedder.setInput(faceBlob)\n",
    "        vec = embedder.forward()\n",
    "\n",
    "        preds = recognizer.predict_proba([vec.flatten()])[0]\n",
    "        j = np.argmax(preds)\n",
    "        proba = preds[j]\n",
    "        name = le.classes_[j] if proba >= recognition_conf_threshold else \"Unknown\"\n",
    "\n",
    "        # === Draw results ===\n",
    "        text = f\"{name} : {proba * 100:.2f}%\"\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 1)\n",
    "        cv2.putText(frame, text, (startX, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 1)\n",
    "\n",
    "        # Print recognition info\n",
    "        if name != \"Unknown\":\n",
    "            print(f\"[INFO] Recognized: {name}, Probability: {proba * 100:.2f}%\")\n",
    "        else:\n",
    "            print(f\"[INFO] Unknown face detected with probability: {proba * 100:.2f}%\")\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.getWindowProperty(\"Frame\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # ESC\n",
    "        break\n",
    "\n",
    "# === Cleanup ===\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa76d3",
   "metadata": {},
   "source": [
    "### ERSGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42b5c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading face detector...\n",
      "[INFO] Loading face embedder...\n",
      "[INFO] Loading recognizer and label encoder...\n",
      "[INFO] Loading Real-ESRGAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonProject\\Face_Recognition_DL\\.venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\PythonProject\\Face_Recognition_DL\\.venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting video stream...\n",
      "\tTile 1/6\n",
      "\tTile 2/6\n",
      "\tTile 3/6\n",
      "\tTile 4/6\n",
      "\tTile 5/6\n",
      "\tTile 6/6\n",
      "[INFO] Recognized: Srijani_Test_Dataset, Probability: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "from realesrgan import RealESRGANer\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "\n",
    "# === Paths ===\n",
    "embeddingModel = r\"D:\\PythonProject\\Face_Recognition_DL\\openface.nn4.small2.v1.t7\"\n",
    "recognizerFile = r\"D:\\PythonProject\\Face_Recognition_DL\\Output_Models\\recognizer_Openface01.pickle\"\n",
    "labelEncFile = r\"D:\\PythonProject\\Face_Recognition_DL\\Output_Models\\LE_Openface01.pickle\"\n",
    "prototxt_path = r\"D:\\PythonProject\\Face_Recognition_DL\\model\\deploy.prototxt.txt\"\n",
    "model_path = r\"D:\\PythonProject\\Face_Recognition_DL\\model\\res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "esrgan_model_path = r\"D:\\PythonProject\\Face_Recognition_DL\\model\\RealESRGAN_x4plus.pth\"\n",
    "\n",
    "# === Configuration ===\n",
    "face_conf_threshold = 0.5\n",
    "recognition_conf_threshold = 0.5\n",
    "\n",
    "# === Load face detector ===\n",
    "print(\"[INFO] Loading face detector...\")\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
    "\n",
    "# === Load face embedder ===\n",
    "print(\"[INFO] Loading face embedder...\")\n",
    "embedder = cv2.dnn.readNetFromTorch(embeddingModel)\n",
    "\n",
    "# === Load recognizer and label encoder ===\n",
    "print(\"[INFO] Loading recognizer and label encoder...\")\n",
    "recognizer = pickle.loads(open(recognizerFile, \"rb\").read())\n",
    "le = pickle.loads(open(labelEncFile, \"rb\").read())\n",
    "\n",
    "# === Load Real-ESRGAN model ===\n",
    "print(\"[INFO] Loading Real-ESRGAN model...\")\n",
    "model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
    "                num_block=23, num_grow_ch=32, scale=4)\n",
    "\n",
    "upscaler = RealESRGANer(\n",
    "    scale=4,\n",
    "    model_path=esrgan_model_path,\n",
    "    model=model,\n",
    "    tile=128,         # Set to 128 for better performance, can try 64 for faster results\n",
    "    tile_pad=10,\n",
    "    pre_pad=0,\n",
    "    half=False,       # True if using GPU with FP16 support\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "\n",
    "# === Start video stream ===\n",
    "print(\"[INFO] Starting video stream...\")\n",
    "cam = cv2.VideoCapture(0)\n",
    "time.sleep(2.0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame for processing efficiency\n",
    "    frame_resized = imutils.resize(frame, width=600)\n",
    "    (h, w) = frame_resized.shape[:2]\n",
    "\n",
    "    # Face detection\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame_resized, (300, 300)), 1.0,\n",
    "                                 (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence < face_conf_threshold:\n",
    "            continue\n",
    "\n",
    "        # Bounding box\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "        face = frame_resized[startY:endY, startX:endX]\n",
    "        (fH, fW) = face.shape[:2]\n",
    "\n",
    "        if fW < 20 or fH < 20:\n",
    "            continue\n",
    "\n",
    "        # === Enhance face using Real-ESRGAN ===\n",
    "        try:\n",
    "            face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            enhanced_rgb, _ = upscaler.enhance(face_rgb, outscale=1)\n",
    "            enhanced_face = cv2.cvtColor(enhanced_rgb, cv2.COLOR_RGB2BGR)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Real-ESRGAN enhancement failed: {e}\")\n",
    "            enhanced_face = face\n",
    "\n",
    "        # === Face embedding and recognition ===\n",
    "        faceBlob = cv2.dnn.blobFromImage(enhanced_face, 1.0 / 255, (96, 96),\n",
    "                                         (0, 0, 0), swapRB=True, crop=False)\n",
    "        embedder.setInput(faceBlob)\n",
    "        vec = embedder.forward()\n",
    "\n",
    "        preds = recognizer.predict_proba([vec.flatten()])[0]\n",
    "        j = np.argmax(preds)\n",
    "        proba = preds[j]\n",
    "        name = le.classes_[j] if proba >= recognition_conf_threshold else \"Unknown\"\n",
    "\n",
    "        # === Draw results ===\n",
    "        text = f\"{name} : {proba * 100:.2f}%\"\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        cv2.rectangle(frame_resized, (startX, startY), (endX, endY), (0, 0, 255), 1)\n",
    "        cv2.putText(frame_resized, text, (startX, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 1)\n",
    "\n",
    "        # Console log\n",
    "        if name != \"Unknown\":\n",
    "            print(f\"[INFO] Recognized: {name}, Probability: {proba * 100:.2f}%\")\n",
    "        else:\n",
    "            print(f\"[INFO] Unknown face detected with probability: {proba * 100:.2f}%\")\n",
    "\n",
    "    # Display the processed frame with detected faces\n",
    "    cv2.imshow(\"Frame\", frame_resized)\n",
    "\n",
    "    # Stop the loop if the user presses 'ESC'\n",
    "    if cv2.getWindowProperty(\"Frame\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # ESC key to exit\n",
    "        break\n",
    "\n",
    "# === Cleanup ===\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8647fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting realesrgan\n",
      "  Using cached realesrgan-0.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: basicsr in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: facexlib>=0.2.5 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from realesrgan) (0.3.0)\n",
      "Requirement already satisfied: gfpgan>=1.3.5 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from realesrgan) (1.3.8)\n",
      "Requirement already satisfied: numpy in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from realesrgan) (1.26.4)\n",
      "Requirement already satisfied: opencv-python in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from realesrgan) (4.11.0.86)\n",
      "Requirement already satisfied: Pillow in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from realesrgan) (11.2.1)\n",
      "Requirement already satisfied: torch>=1.7 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from realesrgan) (1.13.1+cpu)\n",
      "Requirement already satisfied: torchvision in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from realesrgan) (0.14.1+cpu)\n",
      "Requirement already satisfied: tqdm in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from realesrgan) (4.67.1)\n",
      "Requirement already satisfied: addict in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from basicsr) (2.4.0)\n",
      "Requirement already satisfied: future in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from basicsr) (1.0.0)\n",
      "Requirement already satisfied: lmdb in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from basicsr) (1.6.2)\n",
      "Requirement already satisfied: pyyaml in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from basicsr) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from basicsr) (2.32.3)\n",
      "Requirement already satisfied: scikit-image in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from basicsr) (0.25.2)\n",
      "Requirement already satisfied: scipy in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from basicsr) (1.15.2)\n",
      "Requirement already satisfied: tb-nightly in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from basicsr) (2.20.0a20250505)\n",
      "Requirement already satisfied: yapf in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from basicsr) (0.43.0)\n",
      "Requirement already satisfied: filterpy in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from facexlib>=0.2.5->realesrgan) (1.4.5)\n",
      "Requirement already satisfied: numba in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from facexlib>=0.2.5->realesrgan) (0.61.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from torch>=1.7->realesrgan) (4.13.2)\n",
      "Requirement already satisfied: matplotlib in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from filterpy->facexlib>=0.2.5->realesrgan) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (1.17.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from numba->facexlib>=0.2.5->realesrgan) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from requests->basicsr) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from requests->basicsr) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from requests->basicsr) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from requests->basicsr) (2025.4.26)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from scikit-image->basicsr) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from scikit-image->basicsr) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from scikit-image->basicsr) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from scikit-image->basicsr) (0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from tb-nightly->basicsr) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from tb-nightly->basicsr) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from tb-nightly->basicsr) (3.8)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from tb-nightly->basicsr) (6.30.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from tb-nightly->basicsr) (65.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from tb-nightly->basicsr) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from tb-nightly->basicsr) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tb-nightly->basicsr) (3.0.2)\n",
      "Requirement already satisfied: colorama in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from tqdm->realesrgan) (0.4.6)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from yapf->basicsr) (4.3.7)\n",
      "Requirement already satisfied: tomli>=2.0.1 in d:\\pythonproject\\face_recognition_dl\\.venv\\lib\\site-packages (from yapf->basicsr) (2.2.1)\n",
      "Using cached realesrgan-0.3.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: realesrgan\n",
      "Successfully installed realesrgan-0.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install realesrgan basicsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561635e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
